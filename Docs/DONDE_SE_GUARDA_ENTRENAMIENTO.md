# ğŸ“¦ DÃ“NDE SE GUARDA LA INFORMACIÃ“N DE ENTRENAMIENTO Y VALIDACIÃ“N

## ğŸ“‚ ESTRUCTURA DE CARPETAS

Cuando entrenas los modelos de IA, se crean archivos en estas carpetas:

```
chat-bot/
â”œâ”€â”€ models/           â† AQUÃ SE GUARDAN LOS MODELOS ENTRENADOS
â”‚   â”œâ”€â”€ (archivos .h5 y .pkl)
â”œâ”€â”€ data/             â† AQUÃ SE GUARDAN DATASETS
â”‚   â”œâ”€â”€ (archivos .csv)
â”œâ”€â”€ exports/          â† AQUÃ SE EXPORTAN RESULTADOS
â”‚   â”œâ”€â”€ (archivos de anÃ¡lisis)
â””â”€â”€ ...
```

---

## ğŸ§  MODELOS DE PREDICCIÃ“N (predictor.py)

Cuando ejecutas el entrenamiento de predicciÃ³n:

```bash
POST http://localhost:8000/api/entrenar
# O desde cÃ³digo
predictor.entrenar_modelo_tipo_mascota(df)
predictor.guardar_modelos()
```

### Archivos que se crean:

```
models/
â”œâ”€â”€ predictor_model.h5        â† Modelo de red neuronal (.h5 = Keras/TensorFlow)
â””â”€â”€ scaler.pkl                â† StandardScaler + Label Encoders (.pkl = Pickle)
```

### 1. **predictor_model.h5** (Modelo de Red Neuronal)

**Formato:** HDF5 (Hierarchical Data Format)  
**TamaÃ±o:** ~200 KB - 2 MB (depende de la arquitectura)  
**Contiene:**
- Arquitectura de la red (capas, neuronas)
- Pesos entrenados de todas las neuronas
- ConfiguraciÃ³n del optimizador
- FunciÃ³n de pÃ©rdida

**QuÃ© puede hacer:**
- Predecir tipo de mascota segÃºn dÃ­a/hora/servicio
- Predecir probabilidad de asistencia a citas

**Estructura interna:**
```
predictor_model.h5
â”œâ”€â”€ Model Configuration
â”‚   â”œâ”€â”€ Layers: Dense(128) â†’ Dropout(0.3) â†’ Dense(64) â†’ ...
â”‚   â”œâ”€â”€ Activation: ReLU, Softmax
â”‚   â””â”€â”€ Optimizer: Adam
â”œâ”€â”€ Weights (Pesos de las neuronas)
â”‚   â”œâ”€â”€ Layer 1: matriz 4x128 (512 valores)
â”‚   â”œâ”€â”€ Layer 2: matriz 128x64 (8192 valores)
â”‚   â””â”€â”€ ... (miles de parÃ¡metros)
â””â”€â”€ Training Configuration
    â”œâ”€â”€ Loss: categorical_crossentropy
    â””â”€â”€ Metrics: accuracy
```

### 2. **scaler.pkl** (Normalizador + Codificadores)

**Formato:** Pickle (serializaciÃ³n de objetos Python)  
**TamaÃ±o:** ~10-50 KB  
**Contiene:**
```python
{
    'scaler': StandardScaler(),          # NormalizaciÃ³n de features
    'label_encoder_tipo': LabelEncoder()  # CodificaciÃ³n de etiquetas
}
```

**Para quÃ© sirve:**
- **StandardScaler:** Normaliza features antes de predecir
  ```python
  # Transforma valores a media=0, std=1
  [dÃ­a=5, hora=10, mes=11] â†’ [0.23, -0.45, 0.78]
  ```

- **LabelEncoder:** Convierte tipos de mascota a nÃºmeros
  ```python
  "Perro" â†’ 0
  "Gato" â†’ 1
  "Ave" â†’ 2
  ```

---

## ğŸ¤– MODELOS DEL CHATBOT (entrenar_chatbot_veterinario.py)

Cuando ejecutas:

```bash
python entrenar_chatbot_veterinario.py
```

### Archivos que se crean:

```
models/
â”œâ”€â”€ chatbot_veterinario.h5             â† Red neuronal LSTM
â”œâ”€â”€ tokenizer_veterinario.pkl          â† Vocabulario (palabras â†’ nÃºmeros)
â”œâ”€â”€ label_encoder_veterinario.pkl      â† Intenciones â†’ nÃºmeros
â””â”€â”€ intents_veterinario.pkl            â† Diccionario de respuestas
```

### 1. **chatbot_veterinario.h5** (Red LSTM)

**TamaÃ±o:** ~2-5 MB  
**Contiene:**
- Red neuronal LSTM bidireccional
- Embeddings de palabras (5000 palabras x 128 dim)
- Pesos entrenados

**Arquitectura:**
```
Input: Secuencia de palabras [145, 28, 392, 0, 0, ...]
   â†“
Embedding(5000, 128): Convierte nÃºmeros a vectores densos
   â†“
Bidirectional LSTM(64): Procesa secuencia (â†’ y â†)
   â†“
Dropout(0.3): RegularizaciÃ³n
   â†“
Bidirectional LSTM(64): Segunda capa
   â†“
Dense(64, ReLU): Capa densa
   â†“
Dense(num_intenciones, Softmax): ClasificaciÃ³n
   â†“
Output: [0.05, 0.82, 0.03, ...] (probabilidades)
```

### 2. **tokenizer_veterinario.pkl** (Vocabulario)

**TamaÃ±o:** ~50-200 KB  
**Contiene:**
```python
{
    'word_index': {
        'perro': 1,
        'gato': 2,
        'fiebre': 3,
        'vacuna': 4,
        ...
    },
    'num_words': 5000
}
```

**Ejemplo de uso:**
```python
texto = "mi perro tiene fiebre"
tokenizer.texts_to_sequences([texto])
# Resultado: [[45, 1, 28, 3]]
```

### 3. **label_encoder_veterinario.pkl** (Intenciones)

**TamaÃ±o:** ~5-10 KB  
**Contiene:**
```python
{
    'classes_': [
        'saludo',           # 0
        'sintomas',         # 1
        'vacunas',          # 2
        'desparasitacion',  # 3
        ...
    ]
}
```

### 4. **intents_veterinario.pkl** (Respuestas)

**TamaÃ±o:** ~20-100 KB  
**Contiene:**
```python
{
    'saludo': [
        "Â¡Hola! Â¿En quÃ© puedo ayudarte?",
        "Â¡Bienvenido! Soy tu asistente veterinario"
    ],
    'sintomas': [
        "Los sÃ­ntomas que describes requieren atenciÃ³n...",
        "Es importante que consultes con un veterinario..."
    ]
}
```

---

## ğŸ“Š INFORMACIÃ“N DE VALIDACIÃ“N

Durante el entrenamiento, tambiÃ©n se genera informaciÃ³n de validaciÃ³n que **NO se guarda en disco** (solo se muestra en consola):

### MÃ©tricas de Entrenamiento:

```python
# Durante el entrenamiento verÃ¡s:
Epoch 1/50
loss: 2.1234 - accuracy: 0.45 - val_loss: 2.3456 - val_accuracy: 0.42

Epoch 2/50
loss: 1.8567 - accuracy: 0.62 - val_loss: 1.9234 - val_accuracy: 0.58

...

Epoch 50/50
loss: 0.2134 - accuracy: 0.94 - val_loss: 0.2567 - val_accuracy: 0.91
```

**QuÃ© significa:**
- **loss:** FunciÃ³n de pÃ©rdida en datos de entrenamiento (menor = mejor)
- **accuracy:** PrecisiÃ³n en datos de entrenamiento
- **val_loss:** PÃ©rdida en datos de validaciÃ³n (20% separado)
- **val_accuracy:** PrecisiÃ³n en validaciÃ³n (la mÃ¡s importante)

### Si quieres GUARDAR el historial de entrenamiento:

Modifica el cÃ³digo en `predictor.py`:

```python
def entrenar_modelo_tipo_mascota(self, df: pd.DataFrame) -> Dict:
    # ... cÃ³digo de entrenamiento ...
    
    history = self.model_tipo_mascota.fit(...)
    
    # GUARDAR HISTORIAL
    import json
    with open('models/historial_entrenamiento.json', 'w') as f:
        json.dump(history.history, f)
    
    return {
        "accuracy": accuracy,
        "history": history.history  # â† Contiene todo el historial
    }
```

---

## ğŸ—‚ï¸ RESUMEN DE ARCHIVOS GENERADOS

### DespuÃ©s de Entrenar Predictor:

```
models/
â”œâ”€â”€ predictor_model.h5           (Red neuronal para predicciones)
â””â”€â”€ scaler.pkl                   (Normalizador + encoders)
```

**Comando:**
```python
POST http://localhost:8000/api/entrenar
```

**Tiempo:** 5-10 minutos  
**TamaÃ±o total:** ~300 KB - 2 MB

---

### DespuÃ©s de Entrenar Chatbot:

```
models/
â”œâ”€â”€ chatbot_veterinario.h5           (Red LSTM del chatbot)
â”œâ”€â”€ tokenizer_veterinario.pkl        (Vocabulario)
â”œâ”€â”€ label_encoder_veterinario.pkl    (Intenciones)
â””â”€â”€ intents_veterinario.pkl          (Respuestas)
```

**Comando:**
```bash
python entrenar_chatbot_veterinario.py
```

**Tiempo:** 5-10 minutos  
**TamaÃ±o total:** ~2-7 MB

---

### TODOS los modelos juntos:

```
models/
â”œâ”€â”€ predictor_model.h5              # PredicciÃ³n de tipos
â”œâ”€â”€ scaler.pkl                      # Normalizador
â”œâ”€â”€ chatbot_veterinario.h5          # LSTM del chatbot
â”œâ”€â”€ tokenizer_veterinario.pkl       # Vocabulario
â”œâ”€â”€ label_encoder_veterinario.pkl   # Encoder de intenciones
â””â”€â”€ intents_veterinario.pkl         # Diccionario de respuestas
```

---

## ğŸ“ˆ MÃ‰TRICAS DE VALIDACIÃ“N (En Consola)

### Lo que verÃ¡s durante el entrenamiento:

```
ğŸš€ ENTRENANDO MODELO: Tipo de Mascota
================================================================================
ğŸ“Š Preparando datos para predicciÃ³n de tipo de mascota...
âœ“ Datos preparados: 1600 train, 400 test
âœ“ Clases: 7

ğŸ—ï¸  Construyendo modelo de predicciÃ³n de tipo de mascota...
âœ“ Modelo construido

ğŸ“ˆ Entrenando...
Epoch 1/100
50/50 [==============================] - 2s 31ms/step
  loss: 1.8234 
  accuracy: 0.4562 
  val_loss: 1.9123 
  val_accuracy: 0.4325

Epoch 2/100
50/50 [==============================] - 1s 28ms/step
  loss: 1.5421 
  accuracy: 0.5823 
  val_loss: 1.6234 
  val_accuracy: 0.5625

...

Epoch 100/100
50/50 [==============================] - 1s 27ms/step
  loss: 0.2134 
  accuracy: 0.9425 â† PrecisiÃ³n en entrenamiento: 94.25%
  val_loss: 0.2567 
  val_accuracy: 0.9125 â† PrecisiÃ³n en validaciÃ³n: 91.25% â­

ğŸ“Š Evaluando modelo...
âœ“ PrecisiÃ³n en test: 91.25%

ğŸ’¾ Guardando modelos...
âœ“ Modelo tipo mascota guardado
âœ“ Encoders y scaler guardados
```

---

## ğŸ’¾ Â¿QUÃ‰ CONTIENE CADA ARCHIVO?

### .h5 (Modelo de Keras/TensorFlow)

**Formato:** HDF5 (binario)  
**Visualizar:** No es legible como texto  
**Contiene:**
```
/ (raÃ­z)
â”œâ”€â”€ model_weights/
â”‚   â”œâ”€â”€ dense_1/kernel    (matriz de pesos)
â”‚   â”œâ”€â”€ dense_1/bias      (vector de bias)
â”‚   â”œâ”€â”€ lstm_1/kernel     (pesos LSTM)
â”‚   â””â”€â”€ ...
â”œâ”€â”€ model_config/
â”‚   â””â”€â”€ config.json       (arquitectura)
â””â”€â”€ training_config/
    â””â”€â”€ optimizer, loss, metrics
```

**CÃ³mo ver informaciÃ³n:**
```python
from tensorflow.keras.models import load_model

model = load_model('models/predictor_model.h5')
model.summary()  # Muestra arquitectura
```

### .pkl (Pickle - Objetos Python)

**Formato:** Pickle (binario)  
**Contiene:** Objetos Python serializados  
**CÃ³mo ver:**
```python
import pickle

with open('models/scaler.pkl', 'rb') as f:
    data = pickle.load(f)
    print(data.keys())  # dict_keys(['scaler', 'label_encoder_tipo'])
```

---

## ğŸ“Š INFORMACIÃ“N DE VALIDACIÃ“N (NO se guarda por defecto)

### Curvas de Aprendizaje

Durante el entrenamiento se genera el objeto `history`:

```python
history = model.fit(X_train, y_train, validation_split=0.2, epochs=100)

# history.history contiene:
{
    'loss': [2.1, 1.8, 1.5, ..., 0.21],           # PÃ©rdida por Ã©poca (train)
    'accuracy': [0.45, 0.58, 0.67, ..., 0.94],    # PrecisiÃ³n por Ã©poca (train)
    'val_loss': [2.3, 1.9, 1.6, ..., 0.25],       # PÃ©rdida (validation)
    'val_accuracy': [0.42, 0.56, 0.65, ..., 0.91] # PrecisiÃ³n (validation) â­
}
```

### Para guardar las mÃ©tricas de validaciÃ³n:

```python
# Agrega esto en predictor.py despuÃ©s del entrenamiento:
import json

# Guardar historial
with open('models/historial_entrenamiento.json', 'w') as f:
    json.dump(history.history, f, indent=2)

# Guardar reporte de evaluaciÃ³n
with open('models/reporte_evaluacion.txt', 'w') as f:
    f.write(f"PrecisiÃ³n en test: {accuracy:.4f}\n")
    f.write(f"Total de Ã©pocas: {len(history.history['loss'])}\n")
    f.write(f"Loss final: {history.history['loss'][-1]:.4f}\n")
```

### Para graficar curvas de aprendizaje:

```python
import matplotlib.pyplot as plt

# Cargar historial
with open('models/historial_entrenamiento.json') as f:
    history = json.load(f)

# Graficar
plt.plot(history['accuracy'], label='Entrenamiento')
plt.plot(history['val_accuracy'], label='ValidaciÃ³n')
plt.xlabel('Ã‰poca')
plt.ylabel('PrecisiÃ³n')
plt.legend()
plt.savefig('exports/curvas_aprendizaje.png')
```

---

## ğŸ” CÃ“MO VERIFICAR QUE SE GUARDÃ“ CORRECTAMENTE

### OpciÃ³n 1: Desde cÃ³digo Python

```python
import os

# Verificar archivos del predictor
print("Predictor:")
print(f"  Modelo: {os.path.exists('models/predictor_model.h5')}")
print(f"  Scaler: {os.path.exists('models/scaler.pkl')}")

# Verificar archivos del chatbot
print("\nChatbot:")
print(f"  Modelo: {os.path.exists('models/chatbot_veterinario.h5')}")
print(f"  Tokenizer: {os.path.exists('models/tokenizer_veterinario.pkl')}")
print(f"  Encoder: {os.path.exists('models/label_encoder_veterinario.pkl')}")
print(f"  Intents: {os.path.exists('models/intents_veterinario.pkl')}")
```

### OpciÃ³n 2: Desde la API

```bash
# Verificar estado de modelos
GET http://localhost:8000/api/predicciones/estado
```

**Respuesta:**
```json
{
  "modelos_entrenados": true,
  "archivos_modelos": {
    "predictor_model": true,
    "scaler": true
  },
  "todos_listos": true
}
```

### OpciÃ³n 3: Desde terminal

```bash
# Windows
dir models

# Linux/Mac
ls -lh models/
```

**DeberÃ­as ver:**
```
predictor_model.h5              1.2 MB
scaler.pkl                     45 KB
chatbot_veterinario.h5         3.5 MB
tokenizer_veterinario.pkl     120 KB
...
```

---

## ğŸ“¥ CÃ“MO SE CARGAN LOS MODELOS

Cuando inicias la API, automÃ¡ticamente intenta cargar los modelos:

```python
# En api.py (lÃ­nea 45)
try:
    predictor.cargar_modelos()  # â† Carga modelos entrenados
    logger.info("âœ… Modelos cargados exitosamente")
except:
    logger.warning("âš ï¸ Modelos no encontrados. Entrena primero.")
```

**Proceso de carga:**
```python
# predictor.py - cargar_modelos()
def cargar_modelos(self):
    # 1. Cargar modelo de red neuronal
    self.model_tipo_mascota = load_model('models/predictor_model.h5')
    
    # 2. Cargar scaler y encoders
    with open('models/scaler.pkl', 'rb') as f:
        data = pickle.load(f)
        self.scaler = data['scaler']
        self.label_encoder_tipo = data['label_encoder_tipo']
    
    # 3. Marcar como entrenado
    self.trained = True
```

---

## ğŸ¯ RESUMEN PARA TU EXPOSICIÃ“N

### Tipos de Modelos:

| Modelo | Archivo | TamaÃ±o | Algoritmo |
|--------|---------|--------|-----------|
| **Predictor** | predictor_model.h5 | ~1-2 MB | Red Neuronal Densa |
| **Chatbot** | chatbot_veterinario.h5 | ~3-5 MB | LSTM Bidireccional |
| **Clustering** | (No se guarda)* | - | Agglomerative |

*El clustering se ejecuta en tiempo real sobre los datos actuales

### Datos Auxiliares:

| Archivo | QuÃ© guarda | TamaÃ±o |
|---------|------------|--------|
| scaler.pkl | Normalizador (StandardScaler) | ~10 KB |
| tokenizer_veterinario.pkl | Vocabulario (5000 palabras) | ~100 KB |
| label_encoder_veterinario.pkl | Codificador de intenciones | ~5 KB |
| intents_veterinario.pkl | Respuestas predefinidas | ~50 KB |

---

## ğŸ“ PARA INCLUIR EN TU EXPOSICIÃ“N

### Slide: "Persistencia de Modelos"

```
Modelos Entrenados se Guardan en:
  ğŸ“ models/
     â”œâ”€â”€ predictor_model.h5 (1.2 MB)
     â”œâ”€â”€ chatbot_veterinario.h5 (3.5 MB)
     â””â”€â”€ archivos auxiliares (.pkl)

Formato: HDF5 para redes neuronales
         Pickle para objetos Python

Ventajas:
  âœ… Entrenar una vez, usar siempre
  âœ… No re-entrenar en cada inicio
  âœ… Portabilidad entre servidores
```

### Slide: "InformaciÃ³n de ValidaciÃ³n"

```
MÃ©tricas de ValidaciÃ³n (durante entrenamiento):

  â€¢ Accuracy en Test: 91.25%
  â€¢ Loss: 0.2567
  â€¢ Silhouette Score: 0.587 (clustering)
  
DivisiÃ³n de Datos:
  â€¢ 80% Entrenamiento
  â€¢ 20% ValidaciÃ³n
  
Early Stopping: Evita sobreajuste
```

---

## âœ… CHECKLIST

- [ ] Carpeta `models/` existe (se crea automÃ¡ticamente)
- [ ] DespuÃ©s de entrenar, archivos .h5 y .pkl aparecen
- [ ] API carga modelos al iniciar
- [ ] Endpoint `/api/predicciones/estado` retorna `true`

---

## ğŸ‰ RESUMEN

**DÃ³nde se guarda:**
- ğŸ“ `models/` - Todos los modelos entrenados
- Formato: .h5 (Keras) y .pkl (Pickle)

**QuÃ© se guarda:**
- Arquitectura de red
- Pesos entrenados
- Normalizadores y encoders
- Vocabulario (chatbot)

**ValidaciÃ³n:**
- Se muestra en consola durante entrenamiento
- No se guarda por defecto (puedes modificar para guardarlo)

---

**Para tu exposiciÃ³n:** Explica que los modelos se guardan en formato estÃ¡ndar (HDF5) para reutilizarlos sin re-entrenar. ğŸš€

