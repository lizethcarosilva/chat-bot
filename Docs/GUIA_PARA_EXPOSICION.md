# üéì GU√çA PARA EXPOSICI√ìN - SISTEMA PET STORE CON IA

## üìã RESUMEN EJECUTIVO

**Proyecto:** Sistema inteligente para gesti√≥n de Pet Store  
**Tecnolog√≠a:** Python + Machine Learning + API REST  
**Algoritmos de IA:** LSTM, Redes Neuronales, Hierarchical Clustering  

---

## üèóÔ∏è ARQUITECTURA DEL SISTEMA

### Capas del Sistema:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           CAPA DE PRESENTACI√ìN                 ‚îÇ
‚îÇ         Frontend (React/Angular/Vue)           ‚îÇ
‚îÇ   Muestra datos, formularios, dashboards      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ HTTP/REST
                   ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         CAPA DE APLICACI√ìN (api.py)            ‚îÇ
‚îÇ           API REST con FastAPI                 ‚îÇ
‚îÇ   ‚Ä¢ Recibe requests HTTP                       ‚îÇ
‚îÇ   ‚Ä¢ Coordina servicios                         ‚îÇ
‚îÇ   ‚Ä¢ Retorna JSON                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ              ‚îÇ              ‚îÇ
      ‚Üì              ‚Üì              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇchatbot.py‚îÇ  ‚îÇdatabase.py‚îÇ  ‚îÇpredictor.py  ‚îÇ
‚îÇ   (IA)   ‚îÇ  ‚îÇ   (SQL)   ‚îÇ  ‚îÇ  (ML/DL)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ              ‚îÇ              ‚îÇ
      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ   config.py    ‚îÇ
            ‚îÇ (Configuraci√≥n)‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìÇ DESCRIPCI√ìN DE ARCHIVOS .PY

### 1Ô∏è‚É£ **config.py** - Configuraci√≥n Centralizada

**L√≠neas:** ~78  
**Complejidad:** ‚≠ê Baja  

**¬øQu√© hace?**
- Define constantes del sistema
- Configuraci√≥n de base de datos
- Par√°metros de modelos de IA
- Rutas de archivos

**Contenido principal:**
```python
# Conexi√≥n a PostgreSQL
DB_CONFIG = {
    'host': 'gondola.proxy.rlwy.net',
    'port': 22967,
    'database': 'railway',
    'user': 'postgres',
    'password': '***'
}

# Configuraci√≥n de IA
MODEL_CONFIG = {
    'max_words': 5000,      # Vocabulario m√°ximo
    'epochs': 50,           # Ciclos de entrenamiento
    'embedding_dim': 128    # Dimensi√≥n de embeddings
}
```

**Para la exposici√≥n:**
- "Separamos configuraci√≥n del c√≥digo"
- "Facilita cambios entre desarrollo y producci√≥n"

---

### 2Ô∏è‚É£ **database.py** - Capa de Acceso a Datos

**L√≠neas:** ~740  
**Complejidad:** ‚≠ê‚≠ê Media  

**¬øQu√© hace?**
- Conecta a PostgreSQL
- Ejecuta consultas SQL
- Procesa datos con Pandas
- Maneja reconexi√≥n autom√°tica

**M√©todos principales:**

#### Conexi√≥n y Queries
```python
def conectar(self):
    # Establece conexi√≥n con PostgreSQL
    
def ejecutar_query(self, query, params=None):
    # Ejecuta SQL y retorna DataFrame
    # Incluye reconexi√≥n autom√°tica si falla
```

#### M√©tricas de Negocio (NUEVO)
```python
def obtener_citas_hoy(self):
    # SELECT de citas del d√≠a actual
    
def obtener_ventas_dia(self):
    # Calcula ventas diarias con SUM, COUNT
    
def obtener_comparativa_ventas_mensual(self):
    # Compara mes actual vs anterior usando CTE
```

#### An√°lisis Estad√≠stico
```python
def obtener_tipos_mascota_mas_comunes(self):
    # GROUP BY tipo, COUNT, porcentaje
```

**Tecnolog√≠as:**
- **psycopg2:** Driver PostgreSQL para Python
- **Pandas:** Manipulaci√≥n y an√°lisis de datos
- **SQL:** Consultas relacionales

**Para la exposici√≥n:**
- "Capa que abstrae la complejidad de SQL"
- "Retorna datos listos para analizar"
- "Manejo robusto de conexiones"

---

### 3Ô∏è‚É£ **chatbot.py** - Inteligencia Conversacional

**L√≠neas:** ~1201  
**Complejidad:** ‚≠ê‚≠ê‚≠ê‚≠ê Alta  

**¬øQu√© hace?**
- Procesa mensajes en lenguaje natural
- Detecta intenciones del usuario
- Genera respuestas inteligentes
- Puede usar IA (LSTM) o patrones

**Componentes clave:**

#### A. Normalizaci√≥n de Texto
```python
def normalizar_texto(self, texto: str) -> str:
    # Entrada: "¬øCu√°ntos CLIENTES tengo?"
    # Salida: "cuantos clientes tengo"
    #
    # Proceso:
    # 1. Min√∫sculas: "cu√°ntos clientes tengo?"
    # 2. Quitar puntuaci√≥n: "cu√°ntos clientes tengo"
    # 3. Quitar acentos: "cuantos clientes tengo"
    # 4. Normalizar espacios
```

#### B. Detecci√≥n de Intenciones (30+ intenciones)
```python
def detectar_intencion(self, texto: str) -> str:
    # Analiza texto normalizado
    # Busca palabras clave
    # Retorna intenci√≥n detectada
    
    # Ejemplos:
    texto = "cuantos clientes tengo"
    if 'clientes' in texto and 'cuantos' in texto:
        return 'estadisticas'  # ‚Üê Intenci√≥n detectada
```

#### C. Predicci√≥n con Red Neuronal (Opcional)
```python
def predecir_intencion_neuronal(self, texto: str):
    # Usa modelo LSTM entrenado
    # Proceso:
    # 1. Tokeniza texto (palabras ‚Üí n√∫meros)
    # 2. Padding (ajusta longitud)
    # 3. Pasa por red LSTM
    # 4. Softmax da probabilidades por intenci√≥n
    # 5. Retorna intenci√≥n con mayor probabilidad
```

**Modelo LSTM (si est√° entrenado):**
- **Entrada:** Secuencia de palabras
- **Embedding:** Convierte palabras a vectores (128 dim)
- **Bidirectional LSTM:** Procesa secuencia en ambas direcciones
- **Salida:** Probabilidades por cada intenci√≥n

**Para la exposici√≥n:**
- "Dos niveles: Patrones simples + Red neuronal avanzada"
- "LSTM entiende contexto y sin√≥nimos"
- "Maneja 30+ intenciones diferentes"

---

### 4Ô∏è‚É£ **predictor.py** - Machine Learning y Clustering

**L√≠neas:** ~815  
**Complejidad:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Muy Alta  

**¬øQu√© hace?**
- Implementa 3 tipos de algoritmos de IA
- Predice con redes neuronales
- **Agrupa datos con Hierarchical Clustering** üî¨

**Algoritmos implementados:**

#### A. Redes Neuronales para Predicci√≥n
```python
def entrenar_modelo_tipo_mascota(self, df):
    # Red neuronal densa (feedforward)
    # Predice: Tipo de mascota seg√∫n d√≠a/hora/servicio
    
    # Arquitectura:
    # Input (4 features) 
    #   ‚Üí Dense(128, ReLU) 
    #   ‚Üí Dropout(0.3)
    #   ‚Üí Dense(64, ReLU)
    #   ‚Üí Dropout(0.3)
    #   ‚Üí Dense(num_clases, Softmax)
    # Output (probabilidades)
```

#### B. Hierarchical Clustering üî¨ (ESTRELLA DEL PROYECTO)

**Clustering de Mascotas:**
```python
def clustering_mascotas(self, df, n_clusters=3):
    # OBJETIVO: Agrupar mascotas similares
    
    # FEATURES: edad, servicio, precio
    # 
    # ALGORITMO: Agglomerative Hierarchical
    # - Linkage: Ward (minimiza varianza)
    # - M√©trica: Euclidiana
    # 
    # PROCESO:
    # 1. Estandarizar datos (StandardScaler)
    # 2. Aplicar AgglomerativeClustering
    # 3. Evaluar con Silhouette Score
    # 4. Caracterizar cada cluster
    # 
    # RESULTADO:
    # - Cluster 0: Perros j√≥venes (< 2 a√±os)
    # - Cluster 1: Gatos adultos (3-7 a√±os)
    # - Cluster 2: Mascotas senior (> 7 a√±os)
```

**Clustering de Clientes:** (M√ÅS IMPORTANTE)
```python
def clustering_clientes(self, df, n_clusters=4):
    # OBJETIVO: Segmentar clientes por comportamiento
    
    # FEATURES:
    # - total_citas: Frecuencia de visitas
    # - gasto_total: Valor del cliente
    # - tasa_asistencia: Confiabilidad
    # 
    # ALGORITMO: Agglomerative
    # - Linkage: Average
    # - M√©trica: Euclidiana
    # 
    # SEGMENTOS ENCONTRADOS:
    # 1. VIP - Alta frecuencia
    #    ‚Ä¢ Visitas: 8+ citas
    #    ‚Ä¢ Gasto: $800+
    #    ‚Ä¢ Asistencia: 90%+
    #    ‚Üí Estrategia: Programa de lealtad
    # 
    # 2. Regular - Moderado
    #    ‚Ä¢ Visitas: 4-7 citas
    #    ‚Ä¢ Gasto: $300-800
    #    ‚Ä¢ Asistencia: 75-85%
    #    ‚Üí Estrategia: Mantener satisfacci√≥n
    # 
    # 3. Ocasional - Bajo
    #    ‚Ä¢ Visitas: 1-3 citas
    #    ‚Ä¢ Gasto: $100-300
    #    ‚Ä¢ Asistencia: 60-75%
    #    ‚Üí Estrategia: Reactivaci√≥n
    # 
    # 4. Nuevo - Exploratorio
    #    ‚Ä¢ Visitas: 1-2 citas
    #    ‚Ä¢ Gasto: < $100
    #    ‚Ä¢ Asistencia: Variable
    #    ‚Üí Estrategia: Onboarding
```

**M√©trica de Calidad: Silhouette Score**
```python
# F√≥rmula:
s(i) = (b(i) - a(i)) / max(a(i), b(i))

donde:
  a(i) = distancia promedio al mismo cluster
  b(i) = distancia promedio al cluster m√°s cercano

# Interpretaci√≥n:
#  1.0 = Cluster perfecto
#  0.5 = Bien separado
#  0.0 = En el borde
# -1.0 = Probablemente mal asignado
```

**Para la exposici√≥n:**
- "Clustering encuentra grupos autom√°ticamente"
- "No necesita entrenamiento supervisado"
- "√ötil para segmentaci√≥n de clientes"

---

### 5Ô∏è‚É£ **api.py** - Servidor REST

**L√≠neas:** ~1247  
**Complejidad:** ‚≠ê‚≠ê‚≠ê Media-Alta  

**¬øQu√© hace?**
- Servidor web con FastAPI
- Expone 25+ endpoints REST
- Coordina todos los m√≥dulos
- Maneja CORS para frontend

**Endpoints por categor√≠a:**

#### Clustering (NUEVO)
```python
@app.get("/api/clustering/clientes")
async def clustering_clientes(n_clusters: int = 4):
    # 1. Obtiene datos de la BD
    df = db.obtener_dataset_completo()
    
    # 2. Aplica clustering
    resultado = predictor.clustering_clientes(df, n_clusters)
    
    # 3. Retorna JSON
    return resultado
```

#### Chatbot
```python
@app.post("/api/chat")
async def chat(request: ChatRequest):
    # 1. Recibe mensaje del usuario
    # 2. Procesa con chatbot
    # 3. Retorna respuesta + intenci√≥n + confianza
```

#### M√©tricas
```python
@app.get("/api/metricas/dashboard")
async def obtener_dashboard_completo():
    # Retorna todas las m√©tricas en una sola llamada
```

**Tecnolog√≠as:**
- **FastAPI:** Framework web moderno as√≠ncrono
- **Pydantic:** Validaci√≥n autom√°tica de datos
- **Uvicorn:** Servidor ASGI de alto rendimiento

**Para la exposici√≥n:**
- "API REST permite acceso desde cualquier frontend"
- "FastAPI genera documentaci√≥n autom√°tica"
- "Arquitectura as√≠ncrona para mejor rendimiento"

---

### 6Ô∏è‚É£ **entrenar_chatbot_veterinario.py** - Entrenamiento

**L√≠neas:** Variable  
**Complejidad:** ‚≠ê‚≠ê‚≠ê Media  

**¬øQu√© hace?**
- Entrena red neuronal LSTM del chatbot
- Lee ejemplos de `datos_veterinarios.json`
- Guarda modelos entrenados

**Proceso de entrenamiento:**

```python
# 1. CARGAR DATOS
with open('datos_veterinarios.json') as f:
    data = json.load(f)
# Ejemplos: "mi perro tiene fiebre" ‚Üí intenci√≥n: "sintomas"

# 2. TOKENIZACI√ìN
tokenizer = Tokenizer(num_words=5000)
tokenizer.fit_on_texts(patterns)
# Convierte: "perro" ‚Üí 145, "tiene" ‚Üí 28, "fiebre" ‚Üí 392

# 3. PADDING
padded = pad_sequences(sequences, maxlen=50)
# Ajusta todas las secuencias a la misma longitud

# 4. CREAR RED NEURONAL LSTM
model = Sequential([
    Embedding(5000, 128),              # Capa de embeddings
    Bidirectional(LSTM(64)),           # LSTM bidireccional
    Dense(num_intenciones, softmax)    # Clasificaci√≥n
])

# 5. ENTRENAR
model.fit(X_train, y_train, epochs=50)
# Aprende de los ejemplos

# 6. GUARDAR
model.save('models/chatbot_veterinario.h5')
```

**Para la exposici√≥n:**
- "LSTM aprende de ejemplos etiquetados"
- "Proceso de entrenamiento supervisa

do"
- "Mejora con m√°s datos de entrenamiento"

---

### 7Ô∏è‚É£ **verificar_deteccion.py** - Testing

**L√≠neas:** ~90  
**Complejidad:** ‚≠ê Baja  

**¬øQu√© hace?**
- Script de prueba
- Verifica que las detecciones funcionen
- Usado solo en desarrollo

**No incluir en exposici√≥n** (es solo para debugging)

---

## üî¨ ALGORITMO PRINCIPAL: HIERARCHICAL CLUSTERING

### ¬øQu√© es?

Algoritmo de **aprendizaje no supervisado** que agrupa datos similares sin necesidad de etiquetas previas.

### ¬øC√≥mo funciona?

**Proceso Bottom-Up (Agglomerative):**

```
Inicio: N puntos, N clusters
  [C1] [C2] [C3] [C4] [C5] ... [C150]

Iteraci√≥n 1: Une los 2 m√°s cercanos
  [C1-C2] [C3] [C4] [C5] ... [C150]

Iteraci√≥n 2: Une los 2 m√°s cercanos
  [C1-C2-C5] [C3] [C4] ... [C150]

...contin√∫a...

Final: 4 clusters
  [Grupo 1: VIP]  [Grupo 2: Regular]  
  [Grupo 3: Ocasional]  [Grupo 4: Nuevo]
```

### M√©todos de Linkage:

**Ward (usado en mascotas):**
- Minimiza la varianza dentro de cada cluster
- Crea clusters compactos y esf√©ricos

**Average (usado en clientes):**
- Promedio de distancias entre todos los puntos
- Balance entre single y complete

**Complete (usado en servicios):**
- M√°xima distancia entre puntos
- Crea clusters m√°s separados

### F√≥rmula de Distancia Euclidiana:

```
d(p, q) = ‚àö((p‚ÇÅ-q‚ÇÅ)¬≤ + (p‚ÇÇ-q‚ÇÇ)¬≤ + (p‚ÇÉ-q‚ÇÉ)¬≤)

Ejemplo con 2 clientes:
Cliente A: [5 citas, $500 gasto, 0.8 asistencia]
Cliente B: [3 citas, $300 gasto, 0.6 asistencia]

Despu√©s de estandarizar:
Cliente A: [0.5, 0.3, 0.7]
Cliente B: [-0.2, -0.4, -0.5]

Distancia = ‚àö((0.5-(-0.2))¬≤ + (0.3-(-0.4))¬≤ + (0.7-(-0.5))¬≤)
          = ‚àö(0.49 + 0.49 + 1.44)
          = ‚àö2.42
          = 1.56
```

### Silhouette Score - M√©trica de Calidad:

```python
# Para cada punto i:
a(i) = distancia promedio a puntos del mismo cluster
b(i) = distancia promedio al cluster m√°s cercano

silhouette(i) = (b(i) - a(i)) / max(a(i), b(i))

# Promedio de todos los puntos = Silhouette Score global
```

**Interpretaci√≥n visual:**
```
Score = 0.9  ‚Üí  ‚óè‚óè‚óè‚óè‚óè  ¬∑¬∑¬∑¬∑¬∑  ‚óè‚óè‚óè‚óè‚óè  (Muy separados)
Score = 0.5  ‚Üí  ‚óè‚óè‚óè   ¬∑¬∑¬∑¬∑   ‚óè‚óè‚óè‚óè   (Bien separados)
Score = 0.2  ‚Üí  ‚óè‚óè¬∑¬∑‚óè‚óè ¬∑‚óè¬∑¬∑‚óè  ‚óè¬∑¬∑‚óè‚óè  (Solapados)
```

---

## üìä TECNOLOG√çAS DE IA UTILIZADAS

| Tecnolog√≠a | Tipo | D√≥nde se usa | Prop√≥sito |
|------------|------|--------------|-----------|
| **TensorFlow** | Deep Learning | chatbot.py, predictor.py | Redes neuronales |
| **LSTM** | RNN | chatbot.py | Procesamiento de secuencias |
| **scikit-learn** | Machine Learning | predictor.py | Clustering, m√©tricas |
| **AgglomerativeClustering** | Clustering | predictor.py | Agrupamiento jer√°rquico |
| **StandardScaler** | Preprocessing | predictor.py | Normalizaci√≥n |
| **Silhouette Score** | M√©trica | predictor.py | Validaci√≥n de clusters |

---

## üéØ FLUJO COMPLETO: Ejemplo Real

### Usuario pregunta: "clustering"

```
1. FRONTEND
   ‚îî‚îÄ> POST /api/chat
       Body: {"mensaje": "clustering"}

2. API.PY (l√≠nea 135)
   ‚îî‚îÄ> @app.post("/api/chat")
   ‚îî‚îÄ> bot.procesar_mensaje("clustering")

3. CHATBOT.PY (l√≠nea 945)
   ‚îî‚îÄ> normalizar_texto("clustering")
       Resultado: "clustering"
   
   ‚îî‚îÄ> detectar_intencion("clustering")
       Encuentra: "clustering" in texto
       Retorna: 'clustering'
   
   ‚îî‚îÄ> procesar_mensaje() ‚Üí l√≠nea 1078
       elif intencion == 'clustering':
           responder_clustering()

4. CHATBOT.PY ‚Üí responder_clustering() (l√≠nea 887)
   ‚îî‚îÄ> db.obtener_dataset_completo()
       (2000 citas de la BD)
   
   ‚îî‚îÄ> predictor.analisis_clustering_completo(df)

5. PREDICTOR.PY ‚Üí analisis_clustering_completo() (l√≠nea 729)
   ‚îî‚îÄ> clustering_mascotas(df, 3)    # Agrupa mascotas
   ‚îî‚îÄ> clustering_clientes(df, 4)    # Segmenta clientes
   ‚îî‚îÄ> clustering_servicios(df, 3)   # Agrupa servicios

6. PREDICTOR.PY ‚Üí clustering_clientes() (l√≠nea 545)
   # PASO 1: Agrupar por cliente
   clientes_stats = df.groupby('client_id').agg({...})
   
   # PASO 2: Seleccionar features
   X = clientes_stats[['total_citas', 'gasto_total', 'tasa_asistencia']]
   
   # PASO 3: Estandarizar
   X_scaled = StandardScaler().fit_transform(X)
   
   # PASO 4: Clustering
   clustering = AgglomerativeClustering(n_clusters=4, linkage='average')
   labels = clustering.fit_predict(X_scaled)
   
   # PASO 5: Caracterizar segmentos
   for cada segmento:
       calcular promedios
       asignar nombre (VIP, Regular, etc.)
   
   # Retorna JSON con segmentos

7. CHATBOT.PY
   ‚îî‚îÄ> Formatea respuesta bonita con emojis
   ‚îî‚îÄ> Retorna a API

8. API.PY
   ‚îî‚îÄ> Retorna JSON al frontend

9. FRONTEND
   ‚îî‚îÄ> Muestra resultado al usuario
```

---

## üéì PUNTOS CLAVE PARA LA EXPOSICI√ìN

### Slide 1: Introducci√≥n
- Sistema completo de Pet Store
- Backend en Python
- Frontend separado (React/Angular/etc.)

### Slide 2: Arquitectura
- 4 capas: Presentaci√≥n, API, L√≥gica, Datos
- 7 archivos Python con responsabilidades claras

### Slide 3: Tecnolog√≠as de IA
- **LSTM:** Chatbot inteligente
- **Redes Neuronales:** Predicciones
- **Hierarchical Clustering:** Segmentaci√≥n autom√°tica üî¨

### Slide 4: Hierarchical Clustering (DESTACAR)
- Qu√© es: Aprendizaje no supervisado
- C√≥mo funciona: Agglomerative bottom-up
- Aplicaci√≥n: Segmentaci√≥n de clientes

### Slide 5: Resultados
- 4 segmentos de clientes encontrados
- Silhouette Score: 0.587 (Buena calidad)
- Aplicaciones: Marketing, CRM, Retenci√≥n

### Slide 6: Demo
- Mostrar Swagger UI: http://localhost:8000/docs
- Ejecutar: GET /api/clustering/clientes
- Mostrar resultados

---

## üìö ARCHIVOS DE REFERENCIA

| Archivo | Para qu√© leerlo |
|---------|-----------------|
| `EXPLICACION_ARCHIVOS_PARA_EXPOSICION.md` | Resumen de cada archivo |
| `HIERARCHICAL_CLUSTERING_DOCS.md` | Teor√≠a del clustering |
| `ENDPOINTS_CLUSTERING.md` | Endpoints disponibles |

---

## ‚úÖ RESUMEN PARA TU EXPOSICI√ìN

**Sistema:** Pet Store con IA  
**Archivos Python:** 7 (4 principales)  
**Algoritmos de IA:** 3 tipos  
**Destacar:** Hierarchical Clustering para segmentaci√≥n  
**M√©tricas:** Silhouette Score, Accuracy  
**Endpoints:** 25+ servicios REST  

**Mensaje clave:**  
*"Sistema que combina bases de datos, IA y clustering para descubrir patrones autom√°ticamente y segmentar clientes sin supervisi√≥n humana"*

---

**¬°Listo para tu exposici√≥n!** üéìüìäüî¨

