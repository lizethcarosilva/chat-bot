
 PREGUNTAS FRECUENTES - EXPOSICIÓN DE CLUSTERING


Este documento contiene las preguntas MÁS COMUNES que te pueden hacer
en la exposición y cómo responderlas de forma clara y técnica.



1⃣ SOBRE SILHOUETTE SCORE


P: ¿Qué es el Silhouette Score?


R: "Es una métrica de validación que mide la calidad del clustering.
   Evalúa qué tan bien están agrupados los puntos, considerando dos
   factores:
   
   1. Qué tan cerca está cada punto de su propio cluster (cohesión)
   2. Qué tan lejos está del cluster más cercano (separación)
   
   Va de -1 a +1, donde +1 es perfecto, 0 es ambiguo, y negativo
   indica mala asignación."


P: ¿Cómo se calcula?


R: "Para cada punto i, se calcula:
   
   s(i) = (b(i) - a(i)) / max(a(i), b(i))
   
   Donde a(i) es la distancia promedio a puntos del mismo cluster,
   y b(i) es la distancia al cluster más cercano.
   
   El score final es el promedio de todos los s(i).
   
   Intuitivamente, si b es mucho mayor que a (punto está lejos de
   otros clusters), s será cercano a 1. Si a es mayor que b (punto
   está más cerca de otro cluster), s será negativo."


P: ¿Por qué tus scores son bajos (0.2-0.4)?


R: "Hay tres causas principales:
   
   1. MUESTRA PEQUEÑA: 304 mascotas, 102 clientes, 41 servicios.
      Para clustering robusto se recomiendan 1000+ puntos.
   
   2. POCAS FEATURES: Solo uso 3 variables por clustering.
      Más features (5-10) permitirían mejor separación.
   
   3. NATURALEZA DE LOS DATOS: En datos de negocio real, los
      clientes no caen perfectamente en categorías. Hay gradientes
      y solapamientos naturales.
   
   Sin embargo, para mi objetivo (segmentación de negocio, no
   clasificación automática), los clusters SÍ son útiles,
   especialmente el de clientes con 0.36."


P: ¿Un score bajo significa que el clustering es inútil?


R: "No necesariamente. Depende del objetivo:
   
   • Si buscas CLASIFICACIÓN AUTOMÁTICA precisa, scores >0.7 son
     necesarios.
   
   • Si buscas INSIGHTS DE NEGOCIO y segmentación, scores 0.3-0.5
     pueden ser útiles, especialmente si se validan manualmente.
   
   En mi caso, uso el clustering de clientes (0.36) para marketing
   segmentado, donde un poco de ambigüedad es aceptable. Los
   segmentos capturan diferencias reales de comportamiento que son
   accionables para el negocio."



2⃣ SOBRE NÚMERO DE CLUSTERS


P: ¿Cómo elegiste el número de clusters (k)?


R: "Usé una combinación de dos enfoques:
   
   1. ANÁLISIS CUANTITATIVO:
      • Probé diferentes valores de k (2, 3, 4, 5, 6)
      • Calculé el Silhouette Score para cada k
      • Identifiqué el k con mejor score
   
   2. CONOCIMIENTO DEL NEGOCIO:
      • Para clientes: Necesito 4 segmentos para estrategias
        diferenciadas (VIP, Regular, Ocasional, Nuevo)
      • Para mascotas: 3 niveles de precio son interpretables
        (bajo, medio, alto)
      • Para servicios: 3 categorías operativas (rutinario,
        importante, especializado)
   
   Elegí el k que mejor balancea score técnico y utilidad práctica."


P: ¿Por qué no el mismo número en los 3 clustering?


R: "Porque son análisis DIFERENTES con objetivos DIFERENTES:
   
   • MASCOTAS (k=3): Buscamos niveles de precio. 3 es suficiente
     y natural (bajo/medio/alto).
   
   • CLIENTES (k=4): El negocio requiere 4 estrategias de marketing
     diferenciadas. Más clusters fragmentarían, menos perderían
     granularidad necesaria.
   
   • SERVICIOS (k=3): Con solo 41 servicios, más clusters serían
     muy pequeños. 3 categorías operativas son suficientes.
   
   No hay un 'k correcto universal'. Depende de los datos, objetivo
   y aplicación del negocio."


P: ¿Usaste el método del codo (elbow method)?


R: "Sí, lo consideré junto con Silhouette Analysis. El método del
   codo consiste en graficar la inercia (suma de distancias al
   centroide) vs número de clusters, y buscar el 'codo' donde la
   mejora se reduce significativamente.
   
   Sin embargo, en mi caso, el Silhouette Score fue más informativo
   porque mide separación entre clusters, no solo compactación interna.
   
   Además, el conocimiento del negocio fue determinante, especialmente
   para clientes donde la necesidad de 4 segmentos marketing estaba
   clara desde el inicio."



3⃣ SOBRE MÉTODOS DE LINKAGE


P: ¿Por qué usaste diferentes métodos de linkage (Ward, Average, Complete)?


R: "Cada método tiene características diferentes apropiadas para
   distintos tipos de datos:
   
   1. WARD (para mascotas):
      • Minimiza la varianza dentro de cada cluster
      • Crea clusters compactos y de tamaño similar
      • Mejor para variables numéricas continuas (edad, precio)
   
   2. AVERAGE (para clientes):
      • Calcula promedio de distancias entre todos los puntos
      • Más robusto ante outliers que Ward
      • Apropiado cuando hay variabilidad en comportamiento
   
   3. COMPLETE (para servicios):
      • Usa la distancia máxima entre puntos
      • Crea clusters ultra-compactos
      • Asegura que servicios en el mismo grupo sean MUY similares
   
   La elección se basó en la naturaleza de cada dataset y el objetivo
   del clustering."


P: ¿Qué es el método Ward?


R: "Ward es un método de linkage que minimiza el aumento en la suma
   de cuadrados (varianza) cuando se fusionan dos clusters.
   
   En cada paso, une los dos clusters que producen el menor aumento
   en la varianza total. Esto crea clusters muy compactos y tiende
   a producir grupos de tamaño similar.
   
   Es el método más común en clustering jerárquico y funciona bien
   con distancia euclidiana, que es lo que usé."



4⃣ SOBRE LOS RESULTADOS


P: ¿Qué insights obtuviste del clustering de clientes?


R: "Identifiqué 4 segmentos con características claramente diferenciadas:
   
   1. BASE ESTABLE (68 clientes, 67%):
      • Pocas citas (2.5 promedio) pero ASISTEN (70%)
      • Generan el mayor valor total ($10.6M)
      • Estrategia: Mantener satisfacción, son la base del negocio
   
   2. REGULARES (12 clientes, 12%):
      • Frecuencia moderada (6.3 citas)
      • Gasto alto ($422K)
      • Asistencia intermitente (50%)
      • Estrategia: Upselling y mejorar retención
   
   3. INACTIVOS (19 clientes, 19%):
      • Baja frecuencia (1.6 citas)
      • 0% asistencia
      • Estrategia: Campaña de reactivación
   
   4. PROBLEMÁTICOS (3 clientes, 3%):
      • Alta agenda (9 citas) pero baja asistencia (28%)
      • Gasto alto cuando asisten ($599K)
      • Estrategia: Llamada personal para entender el problema
   
   Estos insights permiten estrategias de marketing diferenciadas por
   segmento."


P: ¿Cómo validaste que los clusters son correctos?


R: "Usé tres métodos de validación:
   
   1. SILHOUETTE SCORE: Métrica cuantitativa (0.36 para clientes)
   
   2. VALIDACIÓN DE NEGOCIO: Revisé manualmente clientes de cada
      segmento para verificar que el perfil tenga sentido. Por
      ejemplo, confirmé que los 'VIP' efectivamente tienen alta
      tasa de asistencia.
   
   3. COHERENCIA INTERNA: Verifiqué que clientes dentro del mismo
      segmento tengan características similares y que segmentos
      diferentes se distingan claramente en las variables clave.
   
   Los tres métodos confirmaron que los segmentos son útiles, aunque
   mejoraríamos con más datos y variables."


P: ¿Los nombres (VIP, Regular, etc.) los puso el algoritmo?


R: "No. El algoritmo solo asigna números (Cluster 0, 1, 2, 3) y
   encuentra grupos con características similares.
   
   Los NOMBRES son INTERPRETACIONES HUMANAS basadas en:
   • Características del segmento (frecuencia, gasto, asistencia)
   • Valor para el negocio
   • Estrategia de marketing
   
   Por ejemplo, llamé 'VIP' al segmento 0 porque:
   • Es el más grande (67%)
   • Tiene alta tasa de asistencia (70%)
   • Genera el mayor valor total
   
   Aunque el nombre podría debatirse - algunos dirían que 'Base
   Estable' es más preciso que 'VIP' dada su baja frecuencia.
   
   La interpretación y nomenclatura requiere conocimiento del negocio."



5⃣ SOBRE APLICACIONES


P: ¿Cómo se usan estos clusters en la práctica?


R: "Cada clustering tiene aplicaciones específicas:
   
   CLIENTES:
   • Segmentación de email marketing
   • Diseño de programas de lealtad (VIP gets premium benefits)
   • Campañas de reactivación (para inactivos)
   • Asignación de recursos (más atención a altos valores)
   
   MASCOTAS:
   • Recomendación de servicios (mascotas del cluster 'bajo precio'
      ofrecer paquetes económicos)
   • Predicción de gasto esperado
   • Personalización de comunicación
   
   SERVICIOS:
   • Optimización de horarios (servicios matutinos  staff temprano)
   • Identificación de servicios problemáticos (baja asistencia)
   • Creación de paquetes/combos de servicios similares
   • Estrategias de mejora (recordatorios para servicios con baja
     asistencia)"


P: ¿Cómo integrarías esto en el sistema real?


R: "Hay dos formas:
   
   1. ANÁLISIS BATCH (Actual):
      • Ejecutar clustering periódicamente (mensual/trimestral)
      • Actualizar segmentos de clientes
      • Generar reportes para marketing
      • Ajustar estrategias según cambios
   
   2. CLASIFICACIÓN EN TIEMPO REAL (Futuro):
      • Entrenar un CLASIFICADOR SUPERVISADO usando los clusters
        como etiquetas
      • Asignar nuevos clientes automáticamente a segmentos
      • Actualizar perfil del cliente conforme cambia comportamiento
      • Trigger automático de acciones (email, descuento, etc.)
   
   La segunda opción requiere más infraestructura pero permite
   personalización en tiempo real."



6⃣ SOBRE MEJORAS FUTURAS


P: ¿Cómo mejorarías el Silhouette Score?


R: "Identifico tres áreas de mejora:
   
   1. MÁS DATOS:
      • Objetivo: 1000+ registros por clustering
      • Permite encontrar patrones más claros
      • Reduce ruido estadístico
   
   2. MÁS FEATURES:
      • Clientes: Agregar localización, demografía, canal de
        adquisición, tiempo como cliente, productos comprados
      • Mascotas: Agregar raza, peso, historial médico, urgencias
      • Servicios: Agregar duración, costo, complejidad, veterinario
   
   3. FEATURE ENGINEERING:
      • Crear variables derivadas: ratio gasto/visita, tendencia
        temporal, estacionalidad
      • Normalización más sofisticada
      • Selección de features relevantes
   
   Con estas mejoras, esperaría scores de 0.5-0.7."


P: ¿Consideraste otros algoritmos de clustering?


R: "Sí, consideré varias alternativas:
   
   1. K-MEANS:
      • Más rápido que jerárquico
      • Pero requiere especificar k desde inicio
      • No genera dendrograma (pierde información jerárquica)
   
   2. DBSCAN:
      • No requiere especificar k
      • Encuentra clusters de forma arbitraria
      • Pero sensible a parámetros y no funciona bien con clusters
        de densidad variable
   
   3. GAUSSIAN MIXTURE MODELS:
      • Más flexible que k-means
      • Pero más complejo y requiere más datos
   
   Elegí clustering jerárquico porque:
   • Genera dendrogramas útiles para entender la estructura
   • No requiere especificar k a priori (puedo cortar en cualquier
     nivel)
   • Funciona bien con datasets pequeños
   • Diferentes métodos de linkage ofrecen flexibilidad"



7⃣ PREGUNTAS TÉCNICAS AVANZADAS


P: ¿Por qué usaste distancia euclidiana?


R: "La distancia euclidiana es apropiada cuando:
   • Las features son numéricas continuas (edad, precio, gasto)
   • Las features están en escalas similares (usé StandardScaler
     para normalizar)
   • La magnitud importa (un cliente con $500K gasto está más
     lejos de uno con $100K que uno con $400K)
   
   Otras alternativas como Manhattan o Cosine similarity no eran
   apropiadas porque:
   • Manhattan: Menos sensible a diferencias en features individuales
   • Cosine: Mejor para alta dimensionalidad o cuando solo importa
     dirección, no magnitud"


P: ¿Qué es la linkage matrix?


R: "La linkage matrix es un array que registra la historia completa
   de fusiones en el clustering jerárquico.
   
   Cada fila representa una fusión y contiene:
   [cluster1_id, cluster2_id, distancia, tamaño_nuevo_cluster]
   
   Por ejemplo: [171, 203, 0, 2] significa:
   • Se fusionaron los clusters 171 y 203
   • La distancia entre ellos era 0 (muy similares)
   • El nuevo cluster tiene 2 elementos
   
   Se usa para:
   • Generar dendrogramas (visualización jerárquica)
   • Entender el orden de agrupamiento
   • Validar la elección de k (si distancias crecen mucho, estás
     uniendo grupos muy diferentes)"


P: ¿Cómo manejas outliers?


R: "Outliers pueden afectar el clustering de varias formas:
   
   1. DETECCIÓN:
      • Uso IQR (rango intercuartil) para identificar valores extremos
      • En datos de clientes: Clientes con gasto >>10x la mediana
   
   2. TRATAMIENTO:
      • Para análisis exploratorio: Los mantengo (pueden ser clientes
        VIP legítimos)
      • Si distorsionan mucho: Winsorización (cap en percentil 95/99)
      • Método Average es más robusto ante outliers que Ward
   
   3. ANÁLISIS SEPARADO:
      • Clientes extremos (top 1%) pueden analizarse separadamente
      • No siempre son 'errores', pueden ser casos especiales
   
   En mi dataset, no detecté outliers extremos que requirieran remoción."



8⃣ PREGUNTAS SOBRE ALTERNATIVAS


P: ¿Por qué clustering no supervisado y no clasificación supervisada?


R: "Usé clustering NO supervisado porque:
   
   1. NO TENÍA ETIQUETAS PREVIAS:
      • Nadie había clasificado clientes en VIP/Regular/etc antes
      • No sabía a priori cuántos segmentos existían
      • Buscaba DESCUBRIR patrones, no predecir categorías conocidas
   
   2. OBJETIVO EXPLORATORIO:
      • Entender estructura natural de los datos
      • Identificar segmentos que quizás no había considerado
      • Generar hipótesis sobre comportamiento de clientes
   
   FUTURO: Puedo usar los clusters como ETIQUETAS para entrenar un
   clasificador supervisado, permitiendo asignación automática de
   nuevos clientes a segmentos."


P: ¿Consideraste reducción de dimensionalidad (PCA)?


R: "Lo consideré pero no lo apliqué porque:
   
   1. POCAS DIMENSIONES:
      • Solo uso 3 features por clustering
      • PCA es útil con 10+ features
      • No había redundancia que eliminar
   
   2. INTERPRETABILIDAD:
      • Mis features originales son interpretables (edad, gasto,
        asistencia)
      • PCA genera componentes principales que son combinaciones
        lineales - más difíciles de explicar al negocio
   
   3. NO ERA NECESARIO:
      • El clustering funcionó razonablemente con features originales
      • No había problemas de complejidad computacional
   
   Si tuviera 20+ features, definitivamente usaría PCA para reducir
   dimensionalidad manteniendo 90% de varianza."



9⃣ PREGUNTAS DIFÍCILES/CRÍTICAS


P: ¿No es mejor simplemente usar reglas de negocio simples?


R: "Es una excelente pregunta. Reglas simples como:
   • VIP: >5 citas Y >$500K gasto
   • Regular: 2-5 citas Y $200-500K
   
   SÍ son más simples y más interpretables.
   
   Ventajas de clustering sobre reglas:
   
   1. DESCUBRIMIENTO:
      • Clustering encontró que el 'gasto promedio' no es el único
        factor - la TASA DE ASISTENCIA es crítica
      • Identifiqué el grupo 'problemático' (alta agenda, baja
        asistencia) que no habría encontrado con reglas simples
   
   2. ADAPTABILIDAD:
      • Las reglas fijas se vuelven obsoletas
      • Clustering se ajusta automáticamente a cambios en datos
   
   3. MULTIVARIADO:
      • Considera múltiples variables simultáneamente
      • Reglas simples fallan con interacciones complejas
   
   CONCLUSIÓN: Para esta aplicación, una COMBINACIÓN es mejor:
   • Clustering para explorar y validar segmentos
   • Reglas de negocio claras para implementación operativa"


P: ¿Qué pasa si un cliente cambia de segmento?


R: "Eso es esperado y deseable. Los segmentos NO son fijos:
   
   ESCENARIO:
   • Cliente A empieza como 'Ocasional' (1 cita, bajo gasto)
   • Después de campaña de marketing, aumenta frecuencia
   • En siguiente análisis (trimestral), se reclasifica como 'Regular'
   • Eventualmente puede llegar a 'VIP'
   
   GESTIÓN:
   1. ANÁLISIS PERIÓDICO:
      • Re-ejecutar clustering mensual o trimestralmente
      • Identificar migraciones entre segmentos
      • Ajustar estrategias
   
   2. MÉTRICAS DE ÉXITO:
      • ¿Inactivos se convirtieron en Regulares?  Campaña exitosa
      • ¿Regulares se convirtieron en VIP?  Estrategia funcionó
      • ¿VIP se volvieron Ocasionales?  Problema de retención
   
   3. TRIGGERS AUTOMÁTICOS:
      • Si VIP baja frecuencia  Alert para acción preventiva
      • Si Ocasional aumenta  Oportunidad de upselling
   
   Los cambios de segmento son INFORMACIÓN VALIOSA sobre efectividad
   de estrategias."



 PREGUNTA FINAL TÍPICA


P: Si pudieras hacer UNA cosa para mejorar este proyecto, ¿qué sería?


R: "Implementaría TRACKING TEMPORAL de segmentos.
   
   Actualmente, cada clustering es una 'foto' estática. Lo que falta
   es entender la EVOLUCIÓN:
   
   IMPLEMENTACIÓN:
   1. Ejecutar clustering mensualmente durante 6-12 meses
   2. Rastrear cada cliente individual:
      • Ene: Segmento 2 (Ocasional)
      • Feb: Segmento 2 (Ocasional)
      • Mar: Segmento 1 (Regular)  CAMBIO
      • Abr: Segmento 0 (VIP)  PROGRESO
   
   3. Analizar transiciones:
      • ¿Qué % de Ocasionales se convierten en Regulares?
      • ¿Cuánto tiempo toma pasar de Nuevo a VIP?
      • ¿Qué causó que un VIP se volviera Inactivo?
   
   4. Modelar con MARKOV CHAINS:
      • Probabilidad de transición entre segmentos
      • Predicción de valor lifetime del cliente
      • Identificación temprana de churn
   
   VALOR:
   • Entender el CUSTOMER JOURNEY completo
   • Identificar momentos críticos de intervención
   • Medir ROI de estrategias de marketing
   • Predecir comportamiento futuro
   
   Este sería el siguiente nivel del proyecto."



CONSEJOS FINALES


1. SÉ HONESTO sobre limitaciones (scores bajos, pocos datos)
2. CONECTA con el negocio (no solo matemática, sino aplicación real)
3. MUESTRA CONFIANZA en lo que hiciste (es un buen trabajo)
4. PREPARA ejemplos concretos (cliente X en segmento Y  estrategia Z)
5. ADMITE lo que NO sabes ("No implementé eso, pero investigaría...")

¡ÉXITO EN TU EXPOSICIÓN! 

